# -*- mode: ruby -*-
# vi: set ft=ruby :

Vagrant.configure("2") do |config|
  # Use pre-built PBS box from mcfitz2/proxmox-backup-server
  # The box name will be set by CI workflow (e.g., "pbs-3.4" or "pbs-4.0")
  # For local testing (libvirt provider only), you can manually add a box:
  #   wget https://github.com/mcfitz2/proxmox-backup-server/releases/latest/download/proxmox-backup-server-3.4-amd64-libvirt.box
  #   vagrant box add pbs-3.4 proxmox-backup-server-3.4-amd64-libvirt.box
  config.vm.box = "pbs-3.4"  # Default for local testing, overridden by CI
  
  # Disable default synced folder (not needed for PBS VM, avoids NFS issues in CI)
  config.vm.synced_folder ".", "/vagrant", disabled: true
  
  # PBS VM configuration
  config.vm.define "pbs" do |pbs|
    pbs.vm.hostname = "pbs-test"
    
    # SSH configuration for PBS boxes
    # Connect as vagrant user first (which has working insecure key),
    # then sudo to root for commands
    pbs.ssh.username = "vagrant"
    # Use the Vagrant insecure private key explicitly
    pbs.ssh.insert_key = false
    # The vagrant user has sudo privileges without password
    # PBS API credentials will be root@pam with password "vagrant"
    
    # Increase boot timeout to see more debug output
    pbs.vm.boot_timeout = 600
    
    # Network configuration - forward PBS web interface
    pbs.vm.network "forwarded_port", guest: 8007, host: 8007, host_ip: "127.0.0.1"
    
    # For libvirt, use a private network to ensure proper IP assignment
    # This creates a network with DHCP that the VM can connect to
    pbs.vm.network "private_network", type: "dhcp"
    
    # VM resources - PBS needs reasonable resources
    # VirtualBox provider (for local development on macOS/Windows)
    pbs.vm.provider "virtualbox" do |vb|
      vb.memory = "2048"
      vb.cpus = 2
      vb.name = "pbs-test-vm"
      
      # Create a virtual disk for ZFS pool (4GB) - for testing datastore creation
      unless File.exist?("./zfs-disk.vdi")
        vb.customize ['createhd', '--filename', './zfs-disk.vdi', '--size', 4096]
      end
      vb.customize ['storageattach', :id, '--storagectl', 'SATA Controller', '--port', 1, '--device', 0, '--type', 'hdd', '--medium', './zfs-disk.vdi']
    end
    
    # Libvirt provider (for Linux/GitHub Actions with KVM support)
    pbs.vm.provider "libvirt" do |lv|
      lv.memory = 2048
      lv.cpus = 2
      lv.machine_type = "q35"
      lv.cpu_mode = "host-passthrough"
      
      # Create a virtual disk for ZFS pool (4GB) - for testing datastore creation
      lv.storage :file, :size => '4G', :device => 'vdb', :allow_existing => true
    end
    
    # First provisioner: Diagnostic information about SSH setup
    pbs.vm.provision "shell", name: "ssh-diagnostics", inline: <<-SHELL
      echo "=== SSH Diagnostics ==="
      echo ""
      
      echo "1. Current user and groups:"
      whoami
      id
      echo ""
      
      echo "2. Checking vagrant user SSH setup:"
      ls -la /home/vagrant/.ssh/ || echo "No .ssh directory for vagrant"
      echo ""
      
      echo "3. Checking root user SSH setup:"
      sudo ls -la /root/.ssh/ || echo "No .ssh directory for root"
      echo ""
      
      echo "4. Vagrant user authorized_keys (first 100 chars):"
      head -c 100 /home/vagrant/.ssh/authorized_keys 2>/dev/null || echo "No authorized_keys for vagrant"
      echo ""
      
      echo "5. Root authorized_keys (first 100 chars):"
      sudo head -c 100 /root/.ssh/authorized_keys 2>/dev/null || echo "No authorized_keys for root"
      echo ""
      
      echo "6. SSH daemon configuration (PermitRootLogin):"
      sudo grep "^PermitRootLogin" /etc/ssh/sshd_config || echo "PermitRootLogin not explicitly set"
      echo ""
      
      echo "7. SSH daemon configuration (PubkeyAuthentication):"
      sudo grep "^PubkeyAuthentication" /etc/ssh/sshd_config || echo "PubkeyAuthentication not explicitly set"
      echo ""
      
      echo "8. SSH daemon status:"
      sudo systemctl status ssh 2>/dev/null || sudo systemctl status sshd 2>/dev/null
      echo ""
      
      echo "9. Network interfaces:"
      ip addr show
      echo ""
      
      echo "10. Who can sudo without password:"
      sudo grep -r "NOPASSWD" /etc/sudoers /etc/sudoers.d/ 2>/dev/null
      echo ""
      
      echo "=== End SSH Diagnostics ==="
    SHELL
    
    # Second provisioner: Create a test ZFS pool if additional disk is available
    # The pre-built boxes already have PBS installed and configured
    pbs.vm.provision "shell", name: "setup-zfs-and-pbs", inline: <<-SHELL
      # Check if we have an additional disk for ZFS testing
      if [ -b /dev/vdb ]; then
        echo "Found additional disk /dev/vdb, creating test ZFS pool..."
        
        # Create ZFS pool if it doesn't exist
        if ! zpool list testpool >/dev/null 2>&1; then
          zpool create -f testpool /dev/vdb
          echo "✅ Created ZFS pool 'testpool'"
          zpool list testpool
        else
          echo "ZFS pool 'testpool' already exists"
        fi
      elif [ -b /dev/sdb ]; then
        echo "Found additional disk /dev/sdb, creating test ZFS pool..."
        
        # Create ZFS pool if it doesn't exist
        if ! zpool list testpool >/dev/null 2>&1; then
          zpool create -f testpool /dev/sdb
          echo "✅ Created ZFS pool 'testpool'"
          zpool list testpool
        else
          echo "ZFS pool 'testpool' already exists"
        fi
      else
        echo "⚠️  No additional disk found, skipping test ZFS pool creation"
        echo "Available block devices:"
        lsblk
      fi
      
      # Ensure PBS services are running
      systemctl is-active --quiet proxmox-backup.service || systemctl start proxmox-backup.service
      systemctl is-active --quiet proxmox-backup-proxy.service || systemctl start proxmox-backup-proxy.service
      
      echo "PBS is ready!"
      proxmox-backup-manager version
    SHELL
  end
end
